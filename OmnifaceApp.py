import streamlit as st
import cv2
import numpy as np
import pandas as pd
from PIL import Image
import os
import pickle
import io
from database_manager import get_db_manager

# Simular face_recognition para evitar errores de importaci√≥n
class FaceRecognitionSimulator:
    @staticmethod
    def face_locations(image):
        try:
            # Usar detector de rostros de OpenCV en su lugar
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            
            # Asegurar que la imagen est√° en formato correcto
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            else:
                gray = image
                
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            
            # Convertir formato de OpenCV a formato face_recognition
            locations = []
            for (x, y, w, h) in faces:
                locations.append((y, x + w, y + h, x))  # (top, right, bottom, left)
            return locations
        except Exception as e:
            print(f"Error en face_locations: {e}")
            return []
    
    @staticmethod
    def face_encodings(image, face_locations):
        try:
            # Crear encodings simulados basados en caracter√≠sticas b√°sicas del rostro
            encodings = []
            for location in face_locations:
                top, right, bottom, left = location
                
                # Convertir a enteros normales si son numpy ints
                top = int(top)
                right = int(right)
                bottom = int(bottom)
                left = int(left)
                
                # Validar coordenadas
                height, width = image.shape[:2]
                top = max(0, min(top, height))
                bottom = max(0, min(bottom, height))
                left = max(0, min(left, width))
                right = max(0, min(right, width))
                
                if top < bottom and left < right:
                    face_image = image[top:bottom, left:right]
                    # Crear un encoding simulado usando caracter√≠sticas b√°sicas
                    if face_image.size > 0:
                        # Redimensionar a tama√±o fijo y aplanar como "encoding"
                        face_resized = cv2.resize(face_image, (64, 64))
                        if len(face_resized.shape) == 3:
                            face_resized = cv2.cvtColor(face_resized, cv2.COLOR_RGB2GRAY)
                        
                        encoding = face_resized.flatten().astype(np.float64)
                        # Normalizar el encoding
                        if np.linalg.norm(encoding) > 0:
                            encoding = encoding / np.linalg.norm(encoding)
                        encodings.append(encoding)
            return encodings
        except Exception as e:
            print(f"Error en face_encodings: {e}")
            return []
    
    @staticmethod
    def compare_faces(known_encodings, face_encoding, tolerance=0.6):
        try:
            # Comparar usando distancia euclidiana normalizada
            matches = []
            for known_encoding in known_encodings:
                # Asegurar que ambos encodings tienen la misma dimensi√≥n
                if len(known_encoding) != len(face_encoding):
                    # Redimensionar al tama√±o m√°s peque√±o
                    min_size = min(len(known_encoding), len(face_encoding))
                    known_enc_resized = known_encoding[:min_size]
                    face_enc_resized = face_encoding[:min_size]
                else:
                    known_enc_resized = known_encoding
                    face_enc_resized = face_encoding
                
                # Calcular distancia coseno (mejor para vectores normalizados)
                dot_product = np.dot(known_enc_resized, face_enc_resized)
                norms = np.linalg.norm(known_enc_resized) * np.linalg.norm(face_enc_resized)
                if norms > 0:
                    cosine_similarity = dot_product / norms
                    # Convertir similitud coseno a distancia (0 = igual, 1 = completamente diferente)
                    distance = (1 - cosine_similarity) / 2
                else:
                    distance = 1.0
                
                # Usar tolerancia m√°s estricta para mejor reconocimiento
                matches.append(distance < tolerance)
            return matches
        except Exception as e:
            print(f"Error en compare_faces: {e}")
            return [False] * len(known_encodings)
    
    @staticmethod
    def face_distance(known_encodings, face_encoding):
        try:
            # Calcular distancias coseno normalizadas
            distances = []
            for known_encoding in known_encodings:
                # Asegurar que ambos encodings tienen la misma dimensi√≥n
                if len(known_encoding) != len(face_encoding):
                    # Redimensionar al tama√±o m√°s peque√±o
                    min_size = min(len(known_encoding), len(face_encoding))
                    known_enc_resized = known_encoding[:min_size]
                    face_enc_resized = face_encoding[:min_size]
                else:
                    known_enc_resized = known_encoding
                    face_enc_resized = face_encoding
                
                # Calcular distancia coseno
                dot_product = np.dot(known_enc_resized, face_enc_resized)
                norms = np.linalg.norm(known_enc_resized) * np.linalg.norm(face_enc_resized)
                if norms > 0:
                    cosine_similarity = dot_product / norms
                    # Convertir similitud coseno a distancia
                    distance = (1 - cosine_similarity) / 2
                else:
                    distance = 1.0
                
                distances.append(distance)
            return np.array(distances)
        except Exception as e:
            print(f"Error en face_distance: {e}")
            return np.array([1.0] * len(known_encodings))

# Usar el simulador
face_recognition = FaceRecognitionSimulator()

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="OmniFace - Reconocimiento Facial",
    page_icon="üëÅÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo principal
st.title("üéØ OmniFace - Sistema de Reconocimiento Facial")
st.markdown("---")

# Obtener instancia del manager de base de datos
@st.cache_resource
def get_database_manager():
    return get_db_manager()

db_manager = get_database_manager()

# Funci√≥n para cargar las codificaciones de rostros
def load_encodings():
    return db_manager.get_all_encodings()

# Funci√≥n para cargar la base de datos de personas
def load_database():
    return db_manager.get_all_persons()

# Funci√≥n para guardar persona completa
def save_person_complete(person_id, name, image, encoding):
    return db_manager.save_person(person_id, name, image, encoding)

# Funci√≥n para procesar imagen y obtener codificaci√≥n facial
def get_face_encoding(image):
    try:
        # Convertir imagen PIL a array numpy
        image_array = np.array(image)
        
        # Verificar que la imagen tiene el formato correcto
        if len(image_array.shape) == 3 and image_array.shape[2] == 3:
            # RGB
            pass
        elif len(image_array.shape) == 3 and image_array.shape[2] == 4:
            # RGBA - convertir a RGB
            image_array = image_array[:, :, :3]
        elif len(image_array.shape) == 2:
            # Escala de grises - convertir a RGB
            image_array = cv2.cvtColor(image_array, cv2.COLOR_GRAY2RGB)
        else:
            st.error("Formato de imagen no soportado")
            return None
        
        # Detectar rostros en la imagen
        face_locations = face_recognition.face_locations(image_array)
        
        if len(face_locations) == 0:
            return None
        
        # Obtener codificaci√≥n del primer rostro encontrado
        face_encodings = face_recognition.face_encodings(image_array, face_locations)
        
        if len(face_encodings) > 0:
            return face_encodings[0]
        
        return None
    except Exception as e:
        st.error(f"Error procesando imagen: {e}")
        return None

# Funci√≥n para reconocer rostro
def recognize_face(image, known_encodings):
    face_encoding = get_face_encoding(image)
    
    if face_encoding is None:
        return None, None
    
    # Usar tolerancia m√°s estricta para mayor precisi√≥n
    tolerance = 0.25  # M√°s estricto que 0.4
    min_confidence = 85  # Confianza m√≠nima requerida
    
    best_match = None
    best_confidence = 0
    best_person_id = None
    
    # Comparar con todos los rostros conocidos y encontrar el mejor match
    for person_id, known_encoding in known_encodings.items():
        matches = face_recognition.compare_faces([known_encoding], face_encoding, tolerance=tolerance)
        
        if matches[0]:
            # Calcular distancia y confianza
            distance = face_recognition.face_distance([known_encoding], face_encoding)[0]
            confidence = max(0, (1 - distance * 2.5) * 100)  # F√≥rmula ajustada para mayor precisi√≥n
            
            # Solo considerar si supera la confianza m√≠nima
            if confidence >= min_confidence and confidence > best_confidence:
                best_confidence = confidence
                best_person_id = person_id
                best_match = True
    
    if best_match:
        return best_person_id, best_confidence
    else:
        return None, None

# Sidebar para navegaci√≥n
with st.sidebar:
    st.header("üîß Panel de Control")
    page = st.radio(
        "Selecciona una opci√≥n:",
        ["üìù Gesti√≥n de Base de Datos", "üé• Reconocimiento Facial", "üìä Estad√≠sticas"]
    )

# P√°gina de Gesti√≥n de Base de Datos
if page == "üìù Gesti√≥n de Base de Datos":
    st.header("üìù Gesti√≥n de Base de Datos de Rostros")
    
    # Cargar datos frescos para esta p√°gina
    database = load_database()
    encodings = load_encodings()
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("‚ûï Agregar Nueva Persona")
        
        # Tabs para diferentes m√©todos de captura
        tab1, tab2 = st.tabs(["üìÅ Subir Archivo", "üì∑ Tomar Foto"])
        
        with tab1:
            st.write("**Opci√≥n 1: Subir una imagen desde tu dispositivo**")
            st.info("üí° **Consejos:** Usa im√°genes en formato JPG, JPEG o PNG con buena resoluci√≥n")
            with st.form("add_person_upload_form"):
                person_id_upload = st.text_input("ID de la Persona:", key="id_upload", 
                                                help="Ingresa un identificador √∫nico (ej: 12345678)")
                person_name_upload = st.text_input("Nombre Completo:", key="name_upload",
                                                  help="Nombre completo de la persona")
                uploaded_file = st.file_uploader(
                    "Subir Fotograf√≠a:", 
                    type=['jpg', 'jpeg', 'png'],
                    help="Sube una imagen clara del rostro de la persona"
                )
                
                submitted_upload = st.form_submit_button("üíæ Agregar Persona (Archivo)", 
                                                        use_container_width=True)
        
        with tab2:
            st.write("**Opci√≥n 2: Tomar foto directamente con la c√°mara**")
            st.info("üì∏ **Consejos:** Aseg√∫rate de tener buena iluminaci√≥n y que el rostro est√© centrado")
            with st.form("add_person_camera_form"):
                person_id_camera = st.text_input("ID de la Persona:", key="id_camera",
                                                help="Ingresa un identificador √∫nico (ej: 12345678)")
                person_name_camera = st.text_input("Nombre Completo:", key="name_camera",
                                                  help="Nombre completo de la persona")
                
                st.markdown("**üì∑ Captura de Imagen:**")
                camera_input = st.camera_input("Tomar fotograf√≠a:",
                                              help="Haz clic para activar la c√°mara y tomar una foto")
                
                submitted_camera = st.form_submit_button("üíæ Agregar Persona (Foto)", 
                                                        use_container_width=True)
        
        # Funci√≥n auxiliar para procesar persona
        def process_person(person_id, person_name, image_source, source_type):
            """Procesar y agregar una nueva persona a la base de datos"""
            # Validaciones
            if not person_id:
                st.error("‚ùå Por favor ingresa un ID para la persona")
                return False
            elif not person_name:
                st.error("‚ùå Por favor ingresa el nombre completo")
                return False
            elif image_source is None:
                if source_type == "upload":
                    st.error("‚ùå Por favor sube una fotograf√≠a")
                else:
                    st.error("‚ùå Por favor toma una fotograf√≠a")
                return False
            elif db_manager.person_exists(person_id):
                st.error(f"‚ùå Ya existe una persona con ID '{person_id}'")
                return False
            else:
                try:
                    # Procesar imagen
                    image = Image.open(image_source)
                    st.info("üì∑ Procesando imagen...")
                    
                    # Obtener codificaci√≥n facial
                    face_encoding = get_face_encoding(image)
                    
                    if face_encoding is not None:
                        # Guardar persona completa en Supabase
                        if save_person_complete(person_id, person_name, image, face_encoding):
                            st.success("‚úÖ Datos guardados en la base de datos")
                            st.success("‚úÖ Codificaci√≥n facial guardada")
                            st.success(f"üéâ Persona '{person_name}' agregada exitosamente!")
                            
                            # Mostrar preview de la imagen
                            st.image(image, caption=f"Imagen registrada: {person_name}", width=200)
                            
                            st.info("üîÑ Recarga la p√°gina para ver los cambios en la galer√≠a")
                            return True
                        else:
                            st.error("‚ùå Error guardando en la base de datos")
                            return False
                    else:
                        st.error("‚ùå No se pudo detectar un rostro en la imagen. Intenta con otra foto m√°s clara.")
                        st.info("üí° Consejos: Aseg√∫rate de que el rostro est√© bien iluminado, centrado y sin obstrucciones")
                        return False
                
                except Exception as e:
                    st.error(f"‚ùå Error procesando la solicitud: {str(e)}")
                    st.info("üîß Intenta con una imagen diferente o verifica que el archivo no est√© corrupto")
                    return False
        
        # Procesar formulario de archivo subido
        if submitted_upload:
            process_person(person_id_upload, person_name_upload, uploaded_file, "upload")
        
        # Procesar formulario de c√°mara
        if submitted_camera:
            process_person(person_id_camera, person_name_camera, camera_input, "camera")
        
        # Secci√≥n de ayuda y preview
        st.markdown("---")
        st.subheader("üìã Instrucciones Generales")
        
        with st.expander("üîç Consejos para mejores resultados", expanded=False):
            st.markdown("""
            ### Para obtener el mejor reconocimiento facial:
            
            **üñºÔ∏è Calidad de imagen:**
            - Usa im√°genes con buena resoluci√≥n (m√≠nimo 200x200 p√≠xeles)
            - Evita im√°genes borrosas o pixeladas
            - Formatos soportados: JPG, JPEG, PNG
            
            **üí° Iluminaci√≥n:**
            - Aseg√∫rate de tener buena iluminaci√≥n frontal
            - Evita sombras fuertes en el rostro
            - La luz natural es ideal
            
            **üë§ Posici√≥n del rostro:**
            - El rostro debe estar centrado en la imagen
            - Evita √°ngulos extremos o perfiles
            - Aseg√∫rate de que el rostro est√© completamente visible
            
            **üö´ Evita:**
            - Gafas de sol o m√°scaras
            - Gorros que cubran gran parte del rostro
            - Expresiones faciales extremas
            - M√∫ltiples personas en la misma imagen
            """)
        
        # Preview de imagen capturada
        if 'uploaded_file' in locals() and uploaded_file is not None:
            st.markdown("### üñºÔ∏è Preview de Imagen Subida")
            st.image(uploaded_file, caption="Imagen seleccionada", width=300)
        
        if 'camera_input' in locals() and camera_input is not None:
            st.markdown("### üì∏ Preview de Foto Capturada")
            st.image(camera_input, caption="Foto tomada con c√°mara", width=300)
    
    with col2:
        st.subheader("üë• Base de Datos Actual")
        
        if not database.empty:
            st.dataframe(database[['id', 'nombre']], use_container_width=True)
            
            # Mostrar im√°genes
            st.subheader("üñºÔ∏è Galer√≠a de Rostros")
            cols = st.columns(3)
            
            for idx, row in database.iterrows():
                with cols[idx % 3]:
                    # Obtener imagen desde Supabase
                    image = db_manager.get_person_image(row['id'])
                    if image:
                        st.image(image, caption=f"{row['nombre']} (ID: {row['id']})", use_container_width=True)
                    else:
                        st.error("‚ùå Error cargando imagen")
                    
                    # Bot√≥n para eliminar
                    if st.button(f"üóëÔ∏è Eliminar {row['nombre']}", key=f"delete_{idx}"):
                        # Eliminar de Supabase
                        if db_manager.delete_person(row['id']):
                            st.success(f"‚úÖ Persona '{row['nombre']}' eliminada exitosamente!")
                            st.rerun()
                        else:
                            st.error("‚ùå Error eliminando persona")
        else:
            st.info("üìù No hay personas registradas en la base de datos.")

# P√°gina de Reconocimiento Facial
elif page == "üé• Reconocimiento Facial":
    st.header("üé• Reconocimiento Facial en Tiempo Real")
    
    # Cargar datos frescos para esta p√°gina
    database = load_database()
    encodings = load_encodings()
    
    if database.empty:
        st.warning("‚ö†Ô∏è No hay personas registradas en la base de datos. Ve a la secci√≥n de Gesti√≥n para agregar personas.")
    else:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("üì∑ Capturar Imagen")
            
            # Captura de imagen con c√°mara
            camera_input = st.camera_input("Toma una foto para reconocimiento facial:")
            
            if camera_input is not None:
                # Procesar imagen capturada
                image = Image.open(camera_input)
                st.image(image, caption="Imagen capturada", use_container_width=True)
                
                # Realizar reconocimiento
                with st.spinner("üîç Analizando rostro..."):
                    person_id, confidence = recognize_face(image, encodings)
                
                if person_id is not None:
                    # Buscar informaci√≥n de la persona
                    person_info = database[database['id'] == person_id].iloc[0]
                    
                    with col2:
                        st.subheader("‚úÖ Persona Reconocida")
                        st.success(f"**Nombre:** {person_info['nombre']}")
                        st.info(f"**ID:** {person_info['id']}")
                        st.info(f"**Confianza:** {confidence:.2f}%")
                        
                        # Mostrar imagen de referencia desde Supabase
                        ref_image = db_manager.get_person_image(person_info['id'])
                        if ref_image:
                            st.image(ref_image, caption="Imagen de referencia", use_container_width=True)
                        else:
                            st.warning("‚ö†Ô∏è No se pudo cargar la imagen de referencia")
                        
                        # Mostrar alerta de √©xito basada en confianza
                        if confidence >= 95:
                            st.balloons()
                            st.success("üéØ ¬°Reconocimiento con confianza muy alta!")
                        elif confidence >= 90:
                            st.success("‚úÖ Reconocimiento con confianza alta")
                        elif confidence >= 85:
                            st.info("üëç Reconocimiento con confianza aceptable")
                        else:
                            st.warning("‚ö†Ô∏è Reconocimiento con confianza baja")
                else:
                    with col2:
                        st.subheader("‚ùå No Reconocido")
                        st.error("No se pudo identificar a la persona en la imagen.")
                        st.info("Verifica que la persona est√© registrada en la base de datos.")
        
        with col2:
            if camera_input is None:
                st.subheader("üìã Instrucciones")
                st.markdown("""
                ### C√≥mo usar el reconocimiento facial:
                
                1. **Captura una imagen** usando la c√°mara
                2. **Aseg√∫rate** de que el rostro est√© bien iluminado
                3. **Mant√©n** el rostro centrado en la imagen
                4. **Espera** a que se procese el reconocimiento
                5. **Revisa** los resultados y la confianza
                
                ### Consejos para mejor reconocimiento:
                - Usa buena iluminaci√≥n
                - Mant√©n el rostro sin obstrucciones
                - Evita sombras fuertes
                - Aseg√∫rate de que el rostro est√© enfocado
                """)

# P√°gina de Estad√≠sticas
elif page == "üìä Estad√≠sticas":
    st.header("üìä Estad√≠sticas del Sistema")
    
    # Cargar datos frescos para esta p√°gina
    database = load_database()
    encodings = load_encodings()
    stats = db_manager.get_statistics()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üë• Personas Registradas", stats['total_persons'])
    
    with col2:
        st.metric("üîß Codificaciones Activas", stats['encodings_active'])
    
    with col3:
        st.metric("üíæ Tama√±o Total (MB)", stats['total_size_mb'])
    
    # Tabla de resumen
    if not database.empty:
        st.subheader("üìã Resumen de Base de Datos")
        st.dataframe(database, use_container_width=True)
    
    # Informaci√≥n del sistema
    st.subheader("‚ÑπÔ∏è Informaci√≥n del Sistema")
    st.info("""
    **Sistema de Reconocimiento Facial OmniFace v2.0**
    
    - **Tecnolog√≠a:** OpenCV + Supabase
    - **Base de datos:** Supabase (PostgreSQL)
    - **Almacenamiento:** Cloud (persistente)
    - **Tolerancia:** 0.25 (alta precisi√≥n)
    - **Confianza m√≠nima:** 85%
    - **Formatos soportados:** JPG, JPEG, PNG
    - **Deploy:** Compatible con Streamlit Cloud
    """)

# Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666;'>
        <p>üéØ OmniFace v2.0 - Sistema de Reconocimiento Facial</p>
        <p>Desarrollado con ‚ù§Ô∏è usando Streamlit + Supabase</p>
        <p>üåê <a href="https://github.com/bennminn/Omniface" target="_blank">Ver c√≥digo en GitHub</a></p>
    </div>
    """,
    unsafe_allow_html=True
)